:toc2:
:toc-title: API



= REST Resource: projects.jobs

link:../../index.html[back <<] 


== Resource: Job
Represents a training or prediction job.

JSON representation
{
  "jobId": string,
  "createTime": string,
  "startTime": string,
  "endTime": string,
  "state": enum(State),
  "errorMessage": string,

  // Union field input can be only one of the following:
  "trainingInput": {
    object(TrainingInput)
  },
  "predictionInput": {
    object(PredictionInput)
  }
  // End of list of possible types for union field input.

  // Union field output can be only one of the following:
  "trainingOutput": {
    object(TrainingOutput)
  },
  "predictionOutput": {
    object(PredictionOutput)
  }
  // End of list of possible types for union field output.
}
== Fields
jobId	
string

Required. The user-specified id of the job.

createTime	
string (Timestamp format)

Output only. When the job was created.

A timestamp in RFC3339 UTC "Zulu" format, accurate to nanoseconds. Example: "2014-10-02T15:01:23.045123456Z".

startTime	
string (Timestamp format)

Output only. When the job processing was started.

A timestamp in RFC3339 UTC "Zulu" format, accurate to nanoseconds. Example: "2014-10-02T15:01:23.045123456Z".

endTime	
string (Timestamp format)

Output only. When the job processing was completed.

A timestamp in RFC3339 UTC "Zulu" format, accurate to nanoseconds. Example: "2014-10-02T15:01:23.045123456Z".

state	
enum(State)

Output only. The detailed state of a job.

errorMessage	
string

Output only. The details of a failure or a cancellation.

Union field input. Required. Parameters to create a job. input can be only one of the following:
trainingInput	
object(TrainingInput)

Input parameters to create a training job.

predictionInput	
object(PredictionInput)

Input parameters to create a prediction job.

Union field output. Output only. The current result of the job. output can be only one of the following:
trainingOutput	
object(TrainingOutput)

The current training job result.

predictionOutput	
object(PredictionOutput)

The current prediction job result.

TrainingInput
Represents input parameters for a training job. When using the gcloud command to submit your training job, you can specify the input parameters as command-line arguments and/or in a YAML configuration file referenced from the --config command-line argument. For details, see the guide to submitting a training job.

JSON representation
{
  "scaleTier": enum(ScaleTier),
  "masterType": string,
  "workerType": string,
  "parameterServerType": string,
  "workerCount": string,
  "parameterServerCount": string,
  "packageUris": [
    string
  ],
  "pythonModule": string,
  "args": [
    string
  ],
  "hyperparameters": {
    object(HyperparameterSpec)
  },
  "region": string,
  "jobDir": string,
  "runtimeVersion": string,
  "pythonVersion": string
}
Fields
scaleTier	
enum(ScaleTier)

Required. Specifies the machine types, the number of replicas for workers and parameter servers.

masterType	
string

Optional. Specifies the type of virtual machine to use for your training job's master worker.

The following types are supported:

standard
A basic machine configuration suitable for training simple models with small to moderate datasets.
large_model
A machine with a lot of memory, specially suited for parameter servers when your model is large (having many hidden layers or layers with very large numbers of nodes).
complex_model_s
A machine suitable for the master and workers of the cluster when your model requires more computation than the standard machine can handle satisfactorily.
complex_model_m
A machine with roughly twice the number of cores and roughly double the memory of complex_model_s.
complex_model_l
A machine with roughly twice the number of cores and roughly double the memory of complex_model_m.
standard_gpu
A machine equivalent to standard that also includes a single NVIDIA Tesla K80 GPU. See more about using GPUs to train your model.
complex_model_m_gpu
A machine equivalent to complex_model_m that also includes four NVIDIA Tesla K80 GPUs.
complex_model_l_gpu
A machine equivalent to complex_model_l that also includes eight NVIDIA Tesla K80 GPUs.
standard_p100
A machine equivalent to standard that also includes a single NVIDIA Tesla P100 GPU. The availability of these GPUs is in the Beta launch stage.
complex_model_m_p100
A machine equivalent to complex_model_m that also includes four NVIDIA Tesla P100 GPUs. The availability of these GPUs is in the Beta launch stage.
cloud_tpu
A TPU VM including one Cloud TPU. The availability of Cloud TPU is in Beta launch stage. See more about using TPUs to train your model.
You must set this value when scaleTier is set to CUSTOM.

workerType	
string

Optional. Specifies the type of virtual machine to use for your training job's worker nodes.

The supported values are the same as those described in the entry for masterType.

This value must be present when scaleTier is set to CUSTOM and workerCount is greater than zero.

parameterServerType	
string

Optional. Specifies the type of virtual machine to use for your training job's parameter server.

The supported values are the same as those described in the entry for masterType.

This value must be present when scaleTier is set to CUSTOM and parameterServerCount is greater than zero.

workerCount	
string (int64 format)

Optional. The number of worker replicas to use for the training job. Each replica in the cluster will be of the type specified in workerType.

This value can only be used when scaleTier is set to CUSTOM. If you set this value, you must also set workerType.

parameterServerCount	
string (int64 format)

Optional. The number of parameter server replicas to use for the training job. Each replica in the cluster will be of the type specified in parameterServerType.

This value can only be used when scaleTier is set to CUSTOM.If you set this value, you must also set parameterServerType.

packageUris[]	
string

Required. The Google Cloud Storage location of the packages with the training program and any additional dependencies. The maximum number of package URIs is 100.

pythonModule	
string

Required. The Python module name to run after installing the packages.

args[]	
string

Optional. Command line arguments to pass to the program.

hyperparameters	
object(HyperparameterSpec)

Optional. The set of Hyperparameters to tune.

region	
string

Required. The Google Compute Engine region to run the training job in. See the available regions for ML Engine services.

jobDir	
string

Optional. A Google Cloud Storage path in which to store training outputs and other data needed for training. This path is passed to your TensorFlow program as the '--job-dir' command-line argument. The benefit of specifying this field is that Cloud ML validates the path for use in training.

runtimeVersion	
string

Optional. The Google Cloud ML runtime version to use for training. If not set, Google Cloud ML will choose a stable version, which is defined in the documentation of runtime version list.

pythonVersion	
string

Optional. The version of Python used in training. If not set, the default version is '2.7'. Python '3.5' is available when runtimeVersion is set to '1.4' and above. Python '2.7' works with all supported runtime versions.

ScaleTier
A scale tier is an abstract representation of the resources Cloud ML will allocate to a training job. When selecting a scale tier for your training job, you should consider the size of your training dataset and the complexity of your model. As the tiers increase, virtual machines are added to handle your job, and the individual machines in the cluster generally have more memory and greater processing power than they do at lower tiers. The number of training units charged per hour of processing increases as tiers get more advanced. Refer to the pricing guide for more details. Note that in addition to incurring costs, your use of training resources is constrained by the quota policy.

Enums
BASIC	A single worker instance. This tier is suitable for learning how to use Cloud ML, and for experimenting with new models using small datasets.
STANDARD_1	Many workers and a few parameter servers.
PREMIUM_1	A large number of workers with many parameter servers.
BASIC_GPU	A single worker instance with a GPU.
BASIC_TPU	A single worker instance with a Cloud TPU. The availability of Cloud TPU is in Beta launch stage.
CUSTOM	
The CUSTOM tier is not a set tier, but rather enables you to use your own cluster specification. When you use this tier, set values to configure your processing cluster according to these guidelines:

You must set TrainingInput.masterType to specify the type of machine to use for your master node. This is the only required setting.

You may set TrainingInput.workerCount to specify the number of workers to use. If you specify one or more workers, you must also set TrainingInput.workerType to specify the type of machine to use for your worker nodes.

You may set TrainingInput.parameterServerCount to specify the number of parameter servers to use. If you specify one or more parameter servers, you must also set TrainingInput.parameterServerType to specify the type of machine to use for your parameter servers.

Note that all of your workers must use the same machine type, which can be different from your parameter server type and master type. Your parameter servers must likewise use the same machine type, which can be different from your worker type and master type.

HyperparameterSpec
Represents a set of hyperparameters to optimize.

JSON representation
{
  "goal": enum(GoalType),
  "params": [
    {
      object(ParameterSpec)
    }
  ],
  "maxTrials": number,
  "maxParallelTrials": number,
  "hyperparameterMetricTag": string,
  "resumePreviousJobId": string,
  "enableTrialEarlyStopping": boolean,
  "algorithm": enum(Algorithm)
}
Fields
goal	
enum(GoalType)

Required. The type of goal to use for tuning. Available types are MAXIMIZE and MINIMIZE.

Defaults to MAXIMIZE.

params[]	
object(ParameterSpec)

Required. The set of parameters to tune.

maxTrials	
number

Optional. How many training trials should be attempted to optimize the specified hyperparameters.

Defaults to one.

maxParallelTrials	
number

Optional. The number of training trials to run concurrently. You can reduce the time it takes to perform hyperparameter tuning by adding trials in parallel. However, each trail only benefits from the information gained in completed trials. That means that a trial does not get access to the results of trials running at the same time, which could reduce the quality of the overall optimization.

Each trial will use the same scale tier and machine types.

Defaults to one.

hyperparameterMetricTag	
string

Optional. The Tensorflow summary tag name to use for optimizing trials. For current versions of Tensorflow, this tag name should exactly match what is shown in Tensorboard, including all scopes. For versions of Tensorflow prior to 0.12, this should be only the tag passed to tf.Summary. By default, "training/hptuning/metric" will be used.

resumePreviousJobId	
string

Optional. The prior hyperparameter tuning job id that users hope to continue with. The job id will be used to find the corresponding vizier study guid and resume the study.

enableTrialEarlyStopping	
boolean

Optional. Indicates if the hyperparameter tuning job enables auto trial early stopping.

algorithm	
enum(Algorithm)

Optional. The search algorithm specified for the hyperparameter tuning job. Uses the default CloudML Engine hyperparameter tuning algorithm if unspecified.

GoalType
The available types of optimization goals.

Enums
GOAL_TYPE_UNSPECIFIED	Goal Type will default to maximize.
MAXIMIZE	Maximize the goal metric.
MINIMIZE	Minimize the goal metric.
ParameterSpec
Represents a single hyperparameter to optimize.

JSON representation
{
  "parameterName": string,
  "type": enum(ParameterType),
  "minValue": number,
  "maxValue": number,
  "categoricalValues": [
    string
  ],
  "discreteValues": [
    number
  ],
  "scaleType": enum(ScaleType)
}
Fields
parameterName	
string

Required. The parameter name must be unique amongst all ParameterConfigs in a HyperparameterSpec message. E.g., "learning_rate".

type	
enum(ParameterType)

Required. The type of the parameter.

minValue	
number

Required if type is DOUBLE or INTEGER. This field should be unset if type is CATEGORICAL. This value should be integers if type is INTEGER.

maxValue	
number

Required if type is DOUBLE or INTEGER. This field should be unset if type is CATEGORICAL. This value should be integers if type is INTEGER.

categoricalValues[]	
string

Required if type is CATEGORICAL. The list of possible categories.

discreteValues[]	
number

Required if type is DISCRETE. A list of feasible points. The list should be in strictly increasing order. For instance, this parameter might have possible settings of 1.5, 2.5, and 4.0. This list should not contain more than 1,000 values.

scaleType	
enum(ScaleType)

Optional. How the parameter should be scaled to the hypercube. Leave unset for categorical parameters. Some kind of scaling is strongly recommended for real or integral parameters (e.g., UNIT_LINEAR_SCALE).

ParameterType
The type of the parameter.

Enums
PARAMETER_TYPE_UNSPECIFIED	You must specify a valid type. Using this unspecified type will result in an error.
DOUBLE	Type for real-valued parameters.
INTEGER	Type for integral parameters.
CATEGORICAL	The parameter is categorical, with a value chosen from the categories field.
DISCRETE	The parameter is real valued, with a fixed set of feasible points. If type==DISCRETE, feasible_points must be provided, and {minValue, maxValue} will be ignored.
ScaleType
The type of scaling that should be applied to this parameter.

Enums
NONE	By default, no scaling is applied.
UNIT_LINEAR_SCALE	Scales the feasible space to (0, 1) linearly.
UNIT_LOG_SCALE	Scales the feasible space logarithmically to (0, 1). The entire feasible space must be strictly positive.
UNIT_REVERSE_LOG_SCALE	Scales the feasible space "reverse" logarithmically to (0, 1). The result is that values close to the top of the feasible space are spread out more than points near the bottom. The entire feasible space must be strictly positive.
Algorithm
The available search algorithms of hyperparameter tuning.

Enums
ALGORITHM_UNSPECIFIED	The default algorithm used by hyperparameter tuning service.
GRID_SEARCH	Simple grid search within the feasible space. To use grid search, all parameters must be INTEGER, CATEGORICAL, or DISCRETE.
RANDOM_SEARCH	Simple random search within the feasible space.
PredictionInput
Represents input parameters for a prediction job.

JSON representation
{
  "dataFormat": enum(DataFormat),
  "inputPaths": [
    string
  ],
  "outputPath": string,
  "maxWorkerCount": string,
  "region": string,
  "runtimeVersion": string,
  "batchSize": string,
  "signatureName": string,

  // Union field model_version can be only one of the following:
  "modelName": string,
  "versionName": string,
  "uri": string
  // End of list of possible types for union field model_version.
}
Fields
dataFormat	
enum(DataFormat)

Required. The format of the input data files.

inputPaths[]	
string

Required. The Google Cloud Storage location of the input data files. May contain wildcards.

outputPath	
string

Required. The output Google Cloud Storage location.

maxWorkerCount	
string (int64 format)

Optional. The maximum number of workers to be used for parallel processing. Defaults to 10 if not specified.

region	
string

Required. The Google Compute Engine region to run the prediction job in. See the available regions for ML Engine services.

runtimeVersion	
string

Optional. The Google Cloud ML runtime version to use for this batch prediction. If not set, Google Cloud ML will pick the runtime version used during the versions.create request for this model version, or choose the latest stable version when model version information is not available such as when the model is specified by uri.

batchSize	
string (int64 format)

Optional. Number of records per batch, defaults to 64. The service will buffer batchSize number of records in memory before invoking one Tensorflow prediction call internally. So take the record size and memory available into consideration when setting this parameter.

signatureName	
string

Optional. The name of the signature defined in the SavedModel to use for this job. Please refer to SavedModel for information about how to use signatures.

Defaults to DEFAULT_SERVING_SIGNATURE_DEF_KEY , which is "serving_default".

Union field model_version. Required. The model or the version to use for prediction. model_version can be only one of the following:
modelName	
string

Use this field if you want to use the default version for the specified model. The string must use the following format:

"projects/YOUR_PROJECT/models/YOUR_MODEL"

versionName	
string

Use this field if you want to specify a version of the model to use. The string is formatted the same way as model_version, with the addition of the version information:

"projects/YOUR_PROJECT/models/YOUR_MODEL/versions/YOUR_VERSION"

uri	
string

Use this field if you want to specify a Google Cloud Storage path for the model to use.

DataFormat
The format used to separate data instances in the source and destination files.

Enums
DATA_FORMAT_UNSPECIFIED	Unspecified format.
JSON	Each line of the file is a JSON dictionary representing one record.
TEXT	Deprecated. Use JSON instead.
TF_RECORD	INPUT ONLY. The source file is a TFRecord file.
TF_RECORD_GZIP	INPUT ONLY. The source file is a GZIP-compressed TFRecord file.
State
Describes the job state.

Enums
STATE_UNSPECIFIED	The job state is unspecified.
QUEUED	The job has been just created and processing has not yet begun.
PREPARING	The service is preparing to run the job.
RUNNING	The job is in progress.
SUCCEEDED	The job completed successfully.
FAILED	The job failed. errorMessage should contain the details of the failure.
CANCELLING	The job is being cancelled. errorMessage should describe the reason for the cancellation.
CANCELLED	The job has been cancelled. errorMessage should describe the reason for the cancellation.
TrainingOutput
Represents results of a training job. Output only.

JSON representation
{
  "completedTrialCount": string,
  "trials": [
    {
      object(HyperparameterOutput)
    }
  ],
  "consumedMLUnits": number,
  "isHyperparameterTuningJob": boolean
}
Fields
completedTrialCount	
string (int64 format)

The number of hyperparameter tuning trials that completed successfully. Only set for hyperparameter tuning jobs.

trials[]	
object(HyperparameterOutput)

Results for individual Hyperparameter trials. Only set for hyperparameter tuning jobs.

consumedMLUnits	
number

The amount of ML units consumed by the job.

isHyperparameterTuningJob	
boolean

Whether this job is a hyperparameter tuning job.

HyperparameterOutput
Represents the result of a single hyperparameter tuning trial from a training job. The TrainingOutput object that is returned on successful completion of a training job with hyperparameter tuning includes a list of HyperparameterOutput objects, one for each successful trial.

JSON representation
{
  "trialId": string,
  "hyperparameters": {
    string: string,
    ...
  },
  "finalMetric": {
    object(HyperparameterMetric)
  },
  "isTrialStoppedEarly": boolean,
  "allMetrics": [
    {
      object(HyperparameterMetric)
    }
  ]
}
Fields
trialId	
string

The trial id for these results.

hyperparameters	
map (key: string, value: string)

The hyperparameters given to this trial.

An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.

finalMetric	
object(HyperparameterMetric)

The final objective metric seen for this trial.

isTrialStoppedEarly	
boolean

True if the trial is stopped early.

allMetrics[]	
object(HyperparameterMetric)

All recorded object metrics for this trial. This field is not currently populated.

HyperparameterMetric
An observed value of a metric.

JSON representation
{
  "trainingStep": string,
  "objectiveValue": number
}
Fields
trainingStep	
string (int64 format)

The global training step for this metric.

objectiveValue	
number

The objective value at this training step.

PredictionOutput
Represents results of a prediction job.

JSON representation
{
  "outputPath": string,
  "predictionCount": string,
  "errorCount": string,
  "nodeHours": number
}
Fields
outputPath	
string

The output Google Cloud Storage location provided at the job creation time.

predictionCount	
string (int64 format)

The number of generated predictions.

errorCount	
string (int64 format)

The number of data instances which resulted in errors.

nodeHours	
number

Node hours used by the batch prediction job.

Methods
cancel
Cancels a running job.
create
Creates a training or a batch prediction job.
get
Describes a job.
getIamPolicy
Gets the access control policy for a resource.
list
Lists the jobs in the project.
setIamPolicy
Sets the access control policy on the specified resource.
testIamPermissions
Returns permissions that a caller has on the specified resource.













Method: projects.jobs.cancel
Cancels a running job.

HTTP request
POST https://ml.googleapis.com/v1/{name=projects/*/jobs/*}:cancel

The URL uses Google API HTTP annotation syntax.

Path parameters
Parameters
name	
string

Required. The name of the job to cancel.

Authorization requires the following Google IAM permission on the specified resource name:

ml.jobs.cancel
Request body
The request body must be empty.

Response body
If successful, the response body will be empty.







Method: projects.jobs.create
Creates a training or a batch prediction job.

HTTP request
POST https://ml.googleapis.com/v1/{parent=projects/*}/jobs

The URL uses Google API HTTP annotation syntax.

Path parameters
Parameters
parent	
string

Required. The project name.

Authorization requires the following Google IAM permission on the specified resource parent:

ml.jobs.create
Request body
The request body contains an instance of Job.

Response body
If successful, the response body contains a newly created instance of Job.





Method: projects.jobs.get
Describes a job.

HTTP request
GET https://ml.googleapis.com/v1/{name=projects/*/jobs/*}

The URL uses Google API HTTP annotation syntax.

Path parameters
Parameters
name	
string

Required. The name of the job to get the description of.

Authorization requires the following Google IAM permission on the specified resource name:

ml.jobs.get
Request body
The request body must be empty.

Response body
If successful, the response body contains an instance of Job.







Method: projects.jobs.getIamPolicy
Gets the access control policy for a resource. Returns an empty policy if the resource exists and does not have a policy set.

HTTP request
GET https://ml.googleapis.com/v1/{resource=projects/*/jobs/*}:getIamPolicy

The URL uses Google API HTTP annotation syntax.

Path parameters
Parameters
resource	
string

REQUIRED: The resource for which the policy is being requested. See the operation documentation for the appropriate value for this field.

Request body
The request body must be empty.

Response body
If successful, the response body contains an instance of Policy.





Method: projects.jobs.list
Lists the jobs in the project.

If there are no jobs that match the request parameters, the list request returns an empty response body: {}.

HTTP request
GET https://ml.googleapis.com/v1/{parent=projects/*}/jobs

The URL uses Google API HTTP annotation syntax.

Path parameters
Parameters
parent	
string

Required. The name of the project for which to list jobs.

Authorization requires the following Google IAM permission on the specified resource parent:

ml.jobs.list
Query parameters
Parameters
filter	
string

Optional. Specifies the subset of jobs to retrieve. You can filter on the value of one or more attributes of the job object. For example, retrieve jobs with a job identifier that starts with 'census':

gcloud ml-engine jobs list --filter='jobId:census*'

List all failed jobs with names that start with 'rnn':

gcloud ml-engine jobs list --filter='jobId:rnn* AND state:FAILED'

For more examples, see the guide to monitoring jobs.

pageToken	
string

Optional. A page token to request the next page of results.

You get the token from the nextPageToken field of the response from the previous call.

pageSize	
number

Optional. The number of jobs to retrieve per "page" of results. If there are more remaining results than this number, the response message will contain a valid value in the nextPageToken field.

The default value is 20, and the maximum page size is 100.

Request body
The request body must be empty.

Response body
If successful, the response body contains data with the following structure:

Response message for the jobs.list method.

JSON representation
{
  "jobs": [
    {
      object(Job)
    }
  ],
  "nextPageToken": string
}
Fields
jobs[]	
object(Job)

The list of jobs.

nextPageToken	
string

Optional. Pass this token as the pageToken field of the request for a subsequent call.









Method: projects.jobs.setIamPolicy
Sets the access control policy on the specified resource. Replaces any existing policy.

HTTP request
POST https://ml.googleapis.com/v1/{resource=projects/*/jobs/*}:setIamPolicy

The URL uses Google API HTTP annotation syntax.

Path parameters
Parameters
resource	
string

REQUIRED: The resource for which the policy is being specified. See the operation documentation for the appropriate value for this field.

Request body
The request body contains data with the following structure:

JSON representation
{
  "policy": {
    object(Policy)
  },
  "updateMask": string
}
Fields
policy	
object(Policy)

REQUIRED: The complete policy to be applied to the resource. The size of the policy is limited to a few 10s of KB. An empty policy is a valid policy but certain Cloud Platform services (such as Projects) might reject them.

updateMask	
string (FieldMask format)

OPTIONAL: A FieldMask specifying which fields of the policy to modify. Only the fields in the mask will be modified. If no mask is provided, the following default mask is used: paths: "bindings, etag" This field is only used by Cloud IAM.

A comma-separated list of fully qualified names of fields. Example: "user.displayName,photo".

Response body
If successful, the response body contains an instance of Policy.










Method: projects.jobs.testIamPermissions
Returns permissions that a caller has on the specified resource. If the resource does not exist, this will return an empty set of permissions, not a NOT_FOUND error.

Note: This operation is designed to be used for building permission-aware UIs and command-line tools, not for authorization checking. This operation may "fail open" without warning.

HTTP request
POST https://ml.googleapis.com/v1/{resource=projects/*/jobs/*}:testIamPermissions

The URL uses Google API HTTP annotation syntax.

Path parameters
Parameters
resource	
string

REQUIRED: The resource for which the policy detail is being requested. See the operation documentation for the appropriate value for this field.

Request body
The request body contains data with the following structure:

JSON representation
{
  "permissions": [
    string
  ]
}
Fields
permissions[]	
string

The set of permissions to check for the resource. Permissions with wildcards (such as '*' or 'storage.*') are not allowed. For more information see IAM Overview.

Response body
If successful, the response body contains an instance of TestIamPermissionsResponse.
















